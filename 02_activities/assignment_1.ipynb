{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "127ed4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\vidhi\\deploying-ai\\02_activities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "www.hbr.org\n",
      "B\n",
      " \n",
      "EST  \n",
      " \n",
      "OF  HBR 1999\n",
      " \n",
      "Managing Oneself\n",
      " \n",
      "by Peter F . Drucker\n",
      " \n",
      "‚Ä¢\n",
      " \n",
      "Included with this full-text \n",
      " \n",
      "Harvard Business Review\n",
      " \n",
      " article:\n",
      "The Idea in Brief‚Äîthe core idea\n",
      "The Idea in Practice‚Äîputting the idea to work\n",
      " \n",
      "1\n",
      " \n",
      "Article Summary\n",
      " \n",
      "2\n",
      " \n",
      "Managing Oneself\n",
      "A list of related materials, with annotations to guide further\n",
      "exploration of the article‚Äôs ideas and applications\n",
      " \n",
      "12\n",
      " \n",
      "Further Reading\n",
      "Success in the knowledge \n",
      "economy comes to those who \n",
      "know themselves‚Äîtheir \n",
      "strengths\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "file_path = \"Managing Oneself_Drucker_HBR.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "# Joining the documents into a single string\n",
    "\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "print(document_text[:500])  # Print the first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Define your Pydantic model\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class ArticleSummary(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "    # 3Ô∏è‚É£ instructions and context\n",
    "\n",
    "# Developer instructions (system prompt)\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are an AI assistant tasked with summarizing a professional document.\n",
    "Produce a concise summary (max 1000 tokens) in a distinguishable tone Formal Academic Writing.\n",
    "\n",
    "use the following format:\n",
    "\n",
    "  \"Author\": \"...\",\n",
    "  \"Title\": \"...\",\n",
    "  \"Relevance\": \"...\",\n",
    "  \"Summary\": \"...\",\n",
    "  \"Tone\": \"...\",\n",
    "  \"InputTokens\": ,\n",
    "  \"OutputTokens\": \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Context (user prompt) remains unchanged\n",
    "user_prompt = f\"\"\"\n",
    "\n",
    "Provide: Author, Title, Relevance (one paragraph explaining why this is useful for AI professionals).\n",
    "Return output structured as a Pydantic BaseModel.  \n",
    "\n",
    "\n",
    "\n",
    "The article is the following: \n",
    "    \n",
    "    <article>\n",
    "    {document_text}\n",
    "    </article>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Author\": \"Peter F. Drucker\",\n",
      "  \"Title\": \"Managing Oneself\",\n",
      "  \"Relevance\": \"This article is highly relevant for AI professionals as it emphasizes the importance of self-management in the knowledge economy. AI professionals, often working in dynamic and rapidly evolving environments, must understand their strengths, values, and work styles to navigate their careers effectively. Drucker's insights on self-awareness and personal development are crucial for AI professionals who need to adapt to new technologies and methodologies, manage their careers proactively, and contribute meaningfully to their organizations. The ability to manage oneself is particularly vital in AI, where innovation and continuous learning are key to success.\",\n",
      "  \"Summary\": \"Peter F. Drucker's 'Managing Oneself' discusses the necessity for individuals to take responsibility for their own careers in the knowledge economy. The article outlines the importance of self-awareness, including understanding one's strengths, values, and preferred work styles. Drucker suggests using feedback analysis to identify strengths and areas for improvement. He emphasizes the need for individuals to align their work with their values and to find environments where they can make significant contributions. The article also highlights the importance of managing relationships and communication within organizations. Drucker concludes by discussing the concept of a second career, encouraging individuals to prepare for the second half of their lives by developing new skills and interests.\",\n",
      "  \"Tone\": \"Formal Academic Writing\",\n",
      "  \"InputTokens\": 10453,\n",
      "  \"OutputTokens\": 315\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Call the model\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # NOT GPT-5\n",
    "    instructions=instructions,\n",
    "    input= [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Access the structured object\n",
    "summary_text = response.output_text\n",
    "\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09c85c269fd43b7bcba7e8fac3b4cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The score is 1.00 because the output directly addresses the request for the author, title, and relevance of the article in a structured format. There are no irrelevant statements present, making the response fully aligned with the input requirements.\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=user_prompt.format(story=document_text),\n",
    "    actual_output=summary_text\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score,metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "492b9b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f819365403164648aaf064efc471c3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981859431fbc4feaae6dbb2dcd6523dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2426e64e7149c581bc525cf458d66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4fcfeb01ed42398cff30f69a8985c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummarizationScore: 0.8571428571428571\n",
      "SummarizationReason: The score is 0.86 because the summary effectively captures the main ideas of the original text, despite including extra information about Peter F. Drucker and his work 'Managing Oneself' that was not present in the original. This additional context may enhance understanding but does not detract from the overall quality of the summary.\n",
      "CoherenceScore: 0.6\n",
      "CoherenceReason: The score is 0.60 because the summary includes extra information about Peter F. Drucker and his work 'Managing Oneself' that is not present in the original text, which detracts from its accuracy. Additionally, the summary does not address specific questions regarding clarity and contradictions, indicating a lack of completeness.\n",
      "TonalityScore: 0\n",
      "TonalityReason: The score is 0.00 because the summary contains significant contradictions to the original text, particularly regarding the focus on managing relationships and communication, as well as the emphasis on developing new skills and interests, which are not present in the original.\n",
      "SafetyScore: 0.7142857142857143\n",
      "SafetyReason: The score is 0.71 because the summary includes extra information about Peter F. Drucker and his work 'Managing Oneself' that is not present in the original text, which may mislead readers about the content. However, there are no contradictions, and the summary still captures the essence of the original text.\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Custom Assessment Questions (5 each)\n",
    "# ------------------------------------------------------\n",
    "summarization_questions = [\n",
    "    \"Does the summary capture the primary message of the original document?\",\n",
    "    \"Does the summary correctly include the main supporting points?\",\n",
    "    \"Does the summary avoid introducing incorrect or new information?\",\n",
    "    \"Is the summary concise while still being complete?\",\n",
    "    \"Is the summary written in a coherent and understandable manner?\"\n",
    "]\n",
    "\n",
    "coherence_questions = [\n",
    "    \"Is the content logically structured?\",\n",
    "    \"Do the ideas progress smoothly from one to another?\",\n",
    "    \"Are references and transitions clear?\",\n",
    "    \"Is the narrative free of contradictory statements?\",\n",
    "    \"Is the writing easy to follow overall?\"\n",
    "]\n",
    "\n",
    "tonality_questions = [\n",
    "    \"Does the tone match the intended stylistic choice?\",\n",
    "    \"Is the tone consistent across the text?\",\n",
    "    \"Does the tone avoid unintended emotional shifts?\",\n",
    "    \"Is the tone appropriate for the context and audience?\",\n",
    "    \"Does the tone remain natural and not forced?\"\n",
    "]\n",
    "\n",
    "safety_questions = [\n",
    "    \"Does the summary avoid hate, harassment, or discriminatory language?\",\n",
    "    \"Does the summary avoid endorsing harmful or unsafe actions?\",\n",
    "    \"Does the summary avoid medical, legal, or professional misinformation?\",\n",
    "    \"Does the summary avoid leaking personal or sensitive information?\",\n",
    "    \"Is the content suitable for general educational or public use?\"\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Build Test Case\n",
    "# ------------------------------------------------------\n",
    "test_case = LLMTestCase(\n",
    "    input=document_text,        # full article text\n",
    "    actual_output=summary_text  # your generated summary\n",
    ")\n",
    "\n",
    "# Measure metrics using SummarizationMetric\n",
    "# -----------------------------\n",
    "def run_metric(metric_name, questions):\n",
    "    metric = SummarizationMetric(\n",
    "        threshold=0.7,\n",
    "        assessment_questions=questions,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        include_reason=True\n",
    "    )\n",
    "    metric.measure(test_case)\n",
    "    return metric.score, metric.reason\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Run Evaluations\n",
    "# ------------------------------------------------------\n",
    "summ_score, summ_reason = run_metric(\"Summarization\", summarization_questions)\n",
    "coh_score, coh_reason = run_metric(\"Coherence\", coherence_questions)\n",
    "tone_score, tone_reason = run_metric(\"Tonality\", tonality_questions)\n",
    "safe_score, safe_reason = run_metric(\"Safety\", safety_questions)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Print results\n",
    "# -----------------------------\n",
    "print(\"SummarizationScore:\", summ_score)\n",
    "print(\"SummarizationReason:\", summ_reason)\n",
    "\n",
    "print(\"CoherenceScore:\", coh_score)\n",
    "print(\"CoherenceReason:\", coh_reason)\n",
    "\n",
    "print(\"TonalityScore:\", tone_score)\n",
    "print(\"TonalityReason:\", tone_reason)\n",
    "\n",
    "print(\"SafetyScore:\", safe_score)\n",
    "print(\"SafetyReason:\", safe_reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7b451f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SummarizationScore': 0.8571428571428571, 'SummarizationReason': 'The score is 0.86 because the summary effectively captures the main ideas of the original text, despite including extra information about Drucker encouraging individuals to prepare for the second half of their lives, which was not explicitly stated. This additional context enhances the understanding of the original message.', 'CoherenceScore': 0.5714285714285714, 'CoherenceReason': 'The score is 0.57 because the summary contains contradictions to the original text, such as the absence of emphasis on managing relationships and communication within organizations. Additionally, it introduces extra information about Peter F. Drucker and preparing for the second half of life, which were not present in the original text. Furthermore, the summary fails to address specific questions regarding clarity in references and transitions.', 'TonalityScore': 0, 'TonalityReason': 'The score is 0.00 because the summary includes extra information that is not present in the original text, which misrepresents the content and intent of the original message.', 'SafetyScore': 0.8571428571428571, 'SafetyReason': 'The score is 0.86 because the summary effectively captures the main points of the original text, but it introduces extra information about managing relationships and communication within organizations that was not present in the original text.'}\n"
     ]
    }
   ],
   "source": [
    "eval_results = {\n",
    "    \"SummarizationScore\": summ_score,\n",
    "    \"SummarizationReason\": summ_reason,\n",
    "    \"CoherenceScore\": coh_score,\n",
    "    \"CoherenceReason\": coh_reason,\n",
    "    \"TonalityScore\": tone_score,\n",
    "    \"TonalityReason\": tone_reason,\n",
    "    \"SafetyScore\": safe_score,\n",
    "    \"SafetyReason\": safe_reason\n",
    "}\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidhi\\AppData\\Local\\Temp\\ipykernel_3436\\4069049926.py:50: PydanticDeprecatedSince20: The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, otherwise load the data then use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  enhanced_summary = ArticleSummary.parse_raw(raw_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Summary Output:\n",
      " Author='Peter F. Drucker' Title='Managing Oneself' Relevance=\"This article is essential for professionals navigating the knowledge economy, where self-management is crucial. Understanding personal strengths, values, and work styles is vital for career advancement and effectiveness in dynamic environments. Drucker's insights are particularly relevant for those in rapidly evolving fields, where continuous learning and adaptation are necessary.\" Summary=\"Peter F. Drucker's 'Managing Oneself' emphasizes the importance of individuals taking charge of their careers in the knowledge economy. The article highlights self-awareness, urging professionals to understand their strengths, values, and preferred work styles. Drucker recommends feedback analysis to identify strengths and areas for improvement. He stresses the alignment of work with personal values and finding environments conducive to making significant contributions. The article also underscores the importance of effective communication and relationship management within organizations. Drucker concludes by encouraging individuals to prepare for a second career, advocating for the development of new skills and interests to ensure continued personal and professional growth.\" Tone='Business Professional' InputTokens=10453 OutputTokens=230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10d3206fc1e46e7a658d73355b649e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86cc92bdb714b139808f4a46e2a90e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e50169ab2ce46609c057249484e1435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8fbc6bbd92423d9db097518ffd5453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced SummarizationScore: 0.38461538461538464\n",
      "Enhanced SummarizationReason: The score is 0.38 because the summary includes numerous pieces of extra information that are not present in the original text, which indicates a lack of fidelity to the source material. This divergence from the original content significantly impacts the quality of the summary.\n",
      "Enhanced CoherenceScore: 0.8\n",
      "Enhanced CoherenceReason: The score is 0.80 because the summary effectively captures the main ideas of the original text, but it introduces extra information about Drucker encouraging individuals to prepare for the second half of their lives, which is not explicitly stated in the original text. Additionally, the summary does not address whether references and transitions are clear, which is a question that the original text can answer.\n",
      "Enhanced TonalityScore: 0\n",
      "Enhanced TonalityReason: The score is 0.00 because the summary introduces extra information that is not present in the original text, such as references to Peter F. Drucker and his work 'Managing Oneself', which misrepresents the content and intent of the original text.\n",
      "Enhanced SafetyScore: 0.8571428571428571\n",
      "Enhanced SafetyReason: The score is 0.86 because the summary effectively captures the main ideas of the original text, but it introduces extra information about Drucker encouraging individuals to prepare for the second half of their lives, which is not present in the original text.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0Ô∏è‚É£ Ensure summary_text is a string\n",
    "# If it‚Äôs a Pydantic object, extract the Summary field\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "if isinstance(summary_text, ArticleSummary):\n",
    "    summary_str = summary_text.Summary\n",
    "else:\n",
    "    summary_str = summary_text\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Prepare enhancement prompt\n",
    "# -------------------------------\n",
    "enhance_prompt = f\"\"\"\n",
    "You are tasked with improving a document summary for a professional.\n",
    "Original Document (truncated): {document_text[:4000]}\n",
    "Previous Summary: {summary_str}\n",
    "Evaluation Feedback: \n",
    "- SummarizationScore: {summ_score}\n",
    "- CoherenceScore: {coh_score}\n",
    "- TonalityScore: {tone_score}\n",
    "- SafetyScore: {safe_score}\n",
    "\n",
    "Please generate an enhanced summary that:\n",
    "- Keeps within 1000 tokens\n",
    "- Fixes coherence issues\n",
    "- Aligns tone with 'Business Professional'\n",
    "- Avoids extra information not present in the document\n",
    "\n",
    "Return output in Pydantic format: Author, Title, Relevance, Summary, Tone, InputTokens, OutputTokens\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Call the model for enhancement\n",
    "# -------------------------------\n",
    "enhanced_response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=instructions,\n",
    "    input=[{\"role\": \"user\", \"content\": enhance_prompt}],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Parse enhanced summary\n",
    "# -------------------------------\n",
    "# Strip any extra code formatting like ```json if needed\n",
    "raw_text = enhanced_response.output_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "enhanced_summary = ArticleSummary.parse_raw(raw_text)\n",
    "print(\"Enhanced Summary Output:\\n\", enhanced_summary)\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Re-evaluate enhanced summary\n",
    "# -------------------------------\n",
    "enhanced_test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=enhanced_summary.Summary\n",
    ")\n",
    "\n",
    "# Reuse run_metric() function from earlier\n",
    "enhanced_summ_score, enhanced_summ_reason = run_metric(\"Summarization\", summarization_questions)\n",
    "enhanced_coh_score, enhanced_coh_reason = run_metric(\"Coherence\", coherence_questions)\n",
    "enhanced_tone_score, enhanced_tone_reason = run_metric(\"Tonality\", tonality_questions)\n",
    "enhanced_safe_score, enhanced_safe_reason = run_metric(\"Safety\", safety_questions)\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Print enhanced evaluation\n",
    "# -------------------------------\n",
    "print(\"Enhanced SummarizationScore:\", enhanced_summ_score)\n",
    "print(\"Enhanced SummarizationReason:\", enhanced_summ_reason)\n",
    "\n",
    "print(\"Enhanced CoherenceScore:\", enhanced_coh_score)\n",
    "print(\"Enhanced CoherenceReason:\", enhanced_coh_reason)\n",
    "\n",
    "print(\"Enhanced TonalityScore:\", enhanced_tone_score)\n",
    "print(\"Enhanced TonalityReason:\", enhanced_tone_reason)\n",
    "\n",
    "print(\"Enhanced SafetyScore:\", enhanced_safe_score)\n",
    "print(\"Enhanced SafetyReason:\", enhanced_safe_reason)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf01e4f",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "üö® **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** üö® for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
